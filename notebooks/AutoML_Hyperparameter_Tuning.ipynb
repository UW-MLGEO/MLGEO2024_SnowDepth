{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AtoML and Hyperparameter Tuning\n",
    "\n",
    "Task: Use automated machine learning tools or perform a manual model hyperparameter search to find suitable models and settings for your problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import deep_snow.dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('/mnt/c/Users/JackE/uw/courses/aut24/ml_geo/final_data/classic_ml_val_v1.parquet')\n",
    "scaler = MinMaxScaler()\n",
    "cols_to_normalize = [col for col in df.columns if col != 'aso_sd']\n",
    "df[cols_to_normalize] = scaler.fit_transform(df[cols_to_normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5763835 data samples\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:,0].values\n",
    "data = df.iloc[:, 1:].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split data into 80% train and 20% test subsets\n",
    "print(f\"There are {data.shape[0]} data samples\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do some manual hyperparameter optimization on our Voting Regression model from our regression_analysis notebook\n",
    "\n",
    "Using pycaret as seen in class would be interesting, but due to the lack of support past Python 3.10 (and given our environment is 3.12) and the size of our data, the computational resource constraints would be a bit grueling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Mean Absolute Error: 0.4801591243341718\n",
      "Dummy Regressor Mean Absolute Error: 0.46853125\n",
      "Voting Regressor (Dummy + Ridge) Mean Absolute Error: 0.44280018300508045\n"
     ]
    }
   ],
   "source": [
    "# here is our baseline model found from the previous notebook\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# Ridge Regressor\n",
    "ridge_reg = Ridge()\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "ridge_prediction = ridge_reg.predict(X_test)\n",
    "print(\"Ridge Mean Absolute Error:\", metrics.mean_absolute_error(y_true=y_test, y_pred=ridge_prediction))\n",
    "\n",
    "# Dummy Regressor (Baseline)\n",
    "dummy_reg = DummyRegressor(strategy=\"median\")\n",
    "dummy_reg.fit(X_train, y_train)\n",
    "dummy_prediction = dummy_reg.predict(X_test)\n",
    "print(\"Dummy Regressor Mean Absolute Error:\", metrics.mean_absolute_error(y_true=y_test, y_pred=dummy_prediction))\n",
    "\n",
    "# Voting Regressor (Dummy and Ridge)\n",
    "voting_reg = VotingRegressor(estimators=[('dummy', dummy_reg), ('ridge', ridge_reg)])\n",
    "voting_reg.fit(X_train, y_train)\n",
    "voting_prediction = voting_reg.predict(X_test)\n",
    "print(\"Voting Regressor (Dummy + Ridge) Mean Absolute Error:\", metrics.mean_absolute_error(y_true=y_test, y_pred=voting_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're only going to optimize the hyperparameters on the voting regressor as explained in our regression analysis notebook\n",
    "# the voting regressor model preformed much better than the elastic net and lasso regressor, the lone dummy regressor\n",
    "# and the lone ridge regressor have closer mean absolute errors to the voting regressor, but since the voting regressor is the combination\n",
    "# of the two, we'll *somewhat* in essence be optimizing the hyperparameters on both the ridge and dummy regressor as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimators': [('dummy', DummyRegressor(strategy='median')),\n",
       "  ('ridge', Ridge())],\n",
       " 'n_jobs': None,\n",
       " 'verbose': False,\n",
       " 'weights': None,\n",
       " 'dummy': DummyRegressor(strategy='median'),\n",
       " 'ridge': Ridge(),\n",
       " 'dummy__constant': None,\n",
       " 'dummy__quantile': None,\n",
       " 'dummy__strategy': 'median',\n",
       " 'ridge__alpha': 1.0,\n",
       " 'ridge__copy_X': True,\n",
       " 'ridge__fit_intercept': True,\n",
       " 'ridge__max_iter': None,\n",
       " 'ridge__positive': False,\n",
       " 'ridge__random_state': None,\n",
       " 'ridge__solver': 'auto',\n",
       " 'ridge__tol': 0.0001}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_reg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's start with a gridsearch\n",
    "# ~4 minutes to run\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'ridge__alpha': [0.1, 1.0, 10.0],            # Regularization strength for Ridge\n",
    "    'ridge__fit_intercept': [True, False],        # Whether to calculate the intercept for Ridge\n",
    "    'dummy__strategy': ['mean', 'median'],        # Strategy for filling missing values in the Dummy Regressor\n",
    "    'weights': [[1, 1], [0.5, 1.5], [2, 1]],      # Weights to apply to each regressor in the Voting Regressor\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(voting_reg, param_grid, cv=5, verbose=3, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best Mean Absolute Error:\", -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'dummy__strategy': 'median', 'ridge__alpha': 0.1, 'ridge__fit_intercept': True, 'weights': [1, 1]}\n",
      "Best Mean Absolute Error: 0.44285820530527464\n"
     ]
    }
   ],
   "source": [
    "# collapsed the output of the above cell for notebook display purposes\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best Mean Absolute Error:\", -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's do a random search\n",
    "# ~7 minutes to run\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "param_distributions = {\n",
    "    'ridge__alpha': uniform(0.1, 10),\n",
    "    'ridge__fit_intercept': [True, False],\n",
    "    'dummy__strategy': ['mean', 'median'],\n",
    "    'weights': [[1, 1], [0.5, 1.5], [2, 1]],\n",
    "}\n",
    "random_search = RandomizedSearchCV(\n",
    "    voting_reg,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=100,\n",
    "    random_state=0,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    verbose=3\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"Best parameters found:\", random_search.best_params_)\n",
    "print(\"Best Mean Absolute Error:\", -random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'dummy__strategy': 'median', 'ridge__alpha': 0.19356704856532617, 'ridge__fit_intercept': True, 'weights': [1, 1]}\n",
      "Best Mean Absolute Error: 0.44285839048646203\n"
     ]
    }
   ],
   "source": [
    "# collapsed the output of the above cell for notebook display purposes\n",
    "print(\"Best parameters found:\", random_search.best_params_)\n",
    "print(\"Best Mean Absolute Error:\", -random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see above that the grid search params provide an ever so slightly better mean absolute error than the random search params\n",
    "# though this difference is neglegent. this is understandable as the only difference between the two is the ridge__alpha parameter\n",
    "# which is still quite similar between the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the sake of this assignment, we can safely say that this model is the best in terms of computational resources and time\n",
    "# (and performs the best out of the models we tested)\n",
    "# for the classic ml models we were interested in testing, their computational intake was far too inefficient for even running on\n",
    "# a small subset of the small subset of the data of interest. doing any sort of hyperparameter optimization on those models\n",
    "# trained and tested on the entire dataset would be infeasible and i can't even give an estimate on how many hours\n",
    "# and given the point of this project is to improve upon an existing deep CNN, we thought that exploring faster algorithms would\n",
    "# be more interesting (and realistic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
